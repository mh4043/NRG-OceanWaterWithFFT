<!--
    Traditional way to provide vertex data to a vertex shader is via vertex buffers and attributes.
    Vertex buffers are just like any other WebGPU buffer; they hold data. 
    The difference is we don’t access them directly from the vertex shader. 
    Instead, we tell WebGPU what kind of data is in the buffer and how it’s organized. 
    It then pulls the data out of the buffer and provides it for us.

    Index buffers describe the order to process and use the vertices.
    You can think of draw as going through the vertices in order
    0, 1, 2, 3, 4, 5, .....
    With an index buffer we can change that order.
-->


<canvas width="600" height="600"></canvas>
<!-- 
    If we set width and hight on canvas element (canvas’s drawing buffer) and width and height in CSS (canvas’s display size),
    the display size will be the same size as its drawing buffer, so we dont have to have helper functions for resizing canvas in JS.
    The browser takes our canvas’s drawing buffer size and stretches it to canvas’s display size.
-->
<style>
body {
    background-color: wheat;
}
canvas {
    display: block;  /* make the canvas act like a block   */
    width: 600px;
    height: 600px;
    border: 2px solid black;
    background-color: white;
    margin: auto; /* center horizontally */
}
</style>
<script type="module">
    // WebGPU is an asynchronous API (JS doesn't wait for main to finish executing, but continues)
    async function start() {
        if (!navigator.gpu) {
            fail('this browser does not support WebGPU');
            return;
        }

        const adapter = await navigator.gpu.requestAdapter();
        if (!adapter) {
            fail('this browser supports webgpu but it appears disabled');
            return;
        }

        const device = await adapter?.requestDevice();
        device.lost.then((info) => {
            console.error(`WebGPU device was lost: ${info.message}`);

            // 'reason' will be 'destroyed' if we intentionally destroy the device.
            if (info.reason !== 'destroyed') {
            // try again
            start();
            }
        });
        
        main(device);
    }
    // We use await before function to wait for function to complete
    // await start();
    start();

    // A random number between [min and max)
    // With 1 argument it will be [0 to min)
    // With no arguments it will be [0 to 1)
    const rand = (min, max) => {
        if (min === undefined) {
            min = 0;
            max = 1;
        } else if (max === undefined) {
            max = min;
            min = 0;
        }
        return min + Math.random() * (max - min);
    };

    function createCircleVertices({
        radius = 1,
        numSubdivisions = 24,
        innerRadius = 0,
        startAngle = 0,
        endAngle = Math.PI * 2,
    } = {}) {
        // 2 vertices at each subdivision, + 1 to wrap around the circle.
        const numVertices = (numSubdivisions + 1) * 2;
        // 2 32-bit values for position (xy) and 1 32-bit value for color (rgb)
        // The 32-bit color value will be written/read as 4 8-bit values
        const vertexData = new Float32Array(numVertices * (2 + 1));
        const colorData = new Uint8Array(vertexData.buffer);

        let offset = 0;
        let colorOffset = 8;
        const addVertex = (x, y, r, g, b) => {
            vertexData[offset++] = x;
            vertexData[offset++] = y;
            offset += 1;  // skip the color
            colorData[colorOffset++] = r * 255;
            colorData[colorOffset++] = g * 255;
            colorData[colorOffset++] = b * 255;
            colorOffset += 9;  // skip extra byte and the position
        };

        const innerColor = [1, 1, 1];
        const outerColor = [0.1, 0.1, 0.1];

        // 2 vertices per subdivision
        //
        // 0  2  4  6  8 ...
        //
        // 1  3  5  7  9 ...
        for (let i = 0; i <= numSubdivisions; ++i) {
            const angle = startAngle + (i + 0) * (endAngle - startAngle) / numSubdivisions;

            const c1 = Math.cos(angle);
            const s1 = Math.sin(angle);

            addVertex(c1 * radius, s1 * radius, ...outerColor);
            addVertex(c1 * innerRadius, s1 * innerRadius, ...innerColor);
        }

        const indexData = new Uint32Array(numSubdivisions * 6);
        let ndx = 0;

        // 1st tri  2nd tri  3rd tri  4th tri
        // 0 1 2    2 1 3    4 5 6    6 5 7
        //
        // 0--2        2     4--6        6  .....
        // | /        /|     | /        /|
        // |/        / |     |/        / |
        // 1        1--3     5        5--7  .....
        for (let i = 0; i < numSubdivisions; ++i) {
            const ndxOffset = i * 2;

            // first triangle
            indexData[ndx++] = ndxOffset;
            indexData[ndx++] = ndxOffset + 1;
            indexData[ndx++] = ndxOffset + 2;

            // second triangle
            indexData[ndx++] = ndxOffset + 2;
            indexData[ndx++] = ndxOffset + 1;
            indexData[ndx++] = ndxOffset + 3;
        }

        return {
            vertexData,
            indexData,
            numVertices: indexData.length,
        };
    }

    function main(device) {
        /*  
            "?." => optional chaning operator 
            "?." operator accesses an object's property or calls a function. 
            If the object accessed or function called using this operator is undefined or null, 
            the expression short circuits and evaluates to undefined instead of throwing an error.

            If the navigaor.gpu does not exist, adapter becomes undefined. Adapter represents a specific GPU.
            Some systems have multiple GPUs

            If the adapter is undefined, then by using adapter?, the device will also be undefined.

            Both functions are async, so we need to use await.
        */
        /*
        const adapter = await navigator.gpu?.requestAdapter();
        const device = await adapter?.requestDevice();
        if (!device) {
            fail('This browser does not support WebGPU');
            return;
        }
        */
        /*
        if (!navigator.gpu) {
            fail("WebGPU not supported.");
            return;
        }
        const adapter = await navigator.gpu.requestAdapter({
            powerPreference: 'high-performance'
        });
        if (!adapter) {
            fail("Couldn't request WebGPU adapter.");
            return;
        }
        const device = await adapter.requestDevice();
        */

        /*
            Look up the canvas and create a webgpu context for it. 
            This will let us get a texture to render to. 
            That texture will be used to display the canvas in the webpage.

            Prefered canvas format is eiter rgba8unorm or bgra8unorm.
        */
        // Get a WebGPU context from the canvas and configure it
        const canvas = document.querySelector('canvas');
        const context = canvas.getContext('webgpu');
        const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
        context.configure({
            device,
            format: presentationFormat,
        });

        /*
            Create a shader module. 
            A shader module contains one or more shader functions. 
            In our case, we’ll make 1 vertex shader function and 1 fragment shader function.
        */
        const module = device.createShaderModule({
            label: 'our hardcoded red triangle shaders',
            code: `
            /*
                For a vertex shader, inputs are defined by the @location attributes of the entry point function of the vertex shader.
                For inter stage variables, @location attributes define the location where the variables are passed between shaders
                For fragment shaders, @location specifies which GPURenderPassDescriptor.colorAttachment to store the result in
                (vertex_index) For an indexed draw, the index is equal to the index buffer entry for the vertex, plus the baseVertex argument of the draw, whether provided directly or indirectly
            */

            // @location(number) is used to defined inputs and outputs of shaders
            // Define struct
            // Vertex buffer
            struct Vertex {
                @location(0) position: vec2f,
                @location(1) color: vec4f,
                @location(2) offset: vec2f,
                @location(3) scale: vec2f,
                @location(4) perVertexColor: vec3f,
            };
            struct VSOutput {
                @builtin(position) position: vec4f,
                @location(0) color: vec4f,
            }
        
            // Define a uniform variable outStruct of type OurStructs

            // vertex shader
            /*
                @vertex:                    vertex shader
                fn:                         function
                vs:                         name of function
                @builtin:                   special built-in values that are provided by the WebGPU runtime
                @builtin(vertex_index):     index of the vertex within the vertex buffer (like index in JavaScript's Array.map(function(value, index) { ... }))
                vertexIndex:                parameter (gets value from @builtin(vertex_index))
                u32:                        32-bit unsigned integer (vertexIndex is u32)
                ->:                         returns
                @builtin(position):         final position of a vertex, which the vertex shader writes to (in clip space)
                vec4f:                      a 4D vector of 32bit floating point values ({x: 0, y: 0, z: 0, w: 0}) (returns a position of vec4f type)
                @builtin(instance_index):   When we call draw, we can pass a second argument for number of instances and for each instance drawn, the number of the instance being processed will be passed to our function

                In “triangle-list” mode, every 3 times the vertex shader is executed a triangle will be drawn connecting the 3 position values we return
                Clip space => X goes from -1.0 left to 1.0 right, Y goes from -1.0 bottom to 1.0 top

                Using instanceIndex, we can get specific struct elements from our arrays of structs
            */
           // we can also do this (no need for struct): @vertex fn vs(@location(0) position: vec2f,@location(1) color: vec4f,@location(2) offset: vec2f, @location(3) scale: vec2f, @location(4) perVertexColor: vec3f,
            @vertex fn vs(
                vert: Vertex, 
            ) -> VSOutput {
                var vsOut: VSOutput;
                vsOut.position = vec4f(vert.position * vert.scale + vert.offset, 0.0, 1.0);
                //vsOut.color = vert.color;
                vsOut.color = vert.color * vec4f(vert.perVertexColor, 1);
                return vsOut;
            }
        
            // fragment shader
            /*
                @fragment:      fragment shader
                @location(0):   returns a vec4f at location(0) (writes to the first render target)

                Returns RGBA (vec4f) color (from 0.0 to 1.0 per component)
                Rasterizes the triangle = draws it with pixels

                The fragment shader doesn't have access to @builtin(instance_index)
            */
            @fragment fn fs(vsOut: VSOutput) -> @location(0) vec4f {
                return vsOut.color;
            }
            `,
        });

        /*
            Render pipeline
            layout:auto => ask WebGPU to derive the layout of data from the shaders
            Labels are important!
            vertex => vertex shader (uses "vs" as function for vertex shader from our shader module "module")
            fragment => fragment shader (uses "fs" as function for fragment shader from our shader module "module")
            If there is only one function for vertex shader and one for fragment shader, we dont need to specify "entryPoint"

            When we create the render pipeline, we have to tell WebGPU how to get data for @location(0), for vertex buffer, struct Vertex
            buffers => array which is used to describe how to pull data out of 1 or more vertex buffers
            shaderLocation: 0 => @location(0) in vertex shader, struct Vertex
            arrayStride => how many bytes to get from the data for one vertex in the buffer, to the next vertex in the buffer
            offset: 0  => the data for this attribute starts at byte 0 in the vertex buffer
            format: 'float32x2' => we want WebGPU to pull the data out of the buffer as two 32bit floating point numbers
            stepMode: 'instance' => this attribute will only advance to next value once per instance
            (default is stepMode: 'vertex' which advances once per vertex (and starts over for each instance))

            3 buffer entries => meaning we’re telling WebGPU we’ll supply the data in 3 buffers
            other buffer that holds color and offset, they’re going to be interleaved in the data (color, offset, color, offset, ... stride = color + offset)
        */
        // Create render pipeline
        const pipeline = device.createRenderPipeline({
            label: 'our hardcoded red triangle pipeline',
            layout: 'auto',
            vertex: {
                entryPoint: 'vs',
                module,
                buffers: [
                    {
                        // Vertex buffer (struct Vertex)
                        //arrayStride: 2 * 4, // 2 floats, 4 bytes each (vec2f)
                        //arrayStride: 5 * 4, // 5 floats, 4 bytes each (2bytes of position + 3bytes of perVertexColor (*4 => 1 float has 4 bytes))
                        arrayStride: 2 * 4 + 4, // 2 floats, 4 bytes each + 4 bytes
                        attributes: [
                            {shaderLocation: 0, offset: 0, format: 'float32x2'},  // position
                            //{shaderLocation: 4, offset: 8, format: 'float32x3'},  // perVertexColor (offset = 8: position has 2 32bit(4bytes) floats (2 * 4))
                            {shaderLocation: 4, offset: 8, format: 'unorm8x4'},   // perVertexColor
                        ],
                    },
                    {
                        //arrayStride: 6 * 4, // 6 floats, 4 bytes each
                        arrayStride: 4 + 2 * 4, // 4 bytes + 2 floats, 4 bytes each
                        stepMode: 'instance',
                        attributes: [
                            //{shaderLocation: 1, offset:  0, format: 'float32x4'},  // color
                            //{shaderLocation: 2, offset: 16, format: 'float32x2'},  // offset
                            {shaderLocation: 1, offset: 0, format: 'unorm8x4'},   // color
                            {shaderLocation: 2, offset: 4, format: 'float32x2'},  // offset
                        ],
                    },
                    {
                        arrayStride: 2 * 4, // 2 floats, 4 bytes each
                        stepMode: 'instance',
                        attributes: [
                            {shaderLocation: 3, offset: 0, format: 'float32x2'},   // scale
                        ],
                    },
                ],
            },
            fragment: {
                entryPoint: 'fs',
                module,
                targets: [{ format: presentationFormat }],
            },
        });

        // Fill out a buffer with data that matches the struct in our shader.
        /*
            GPUBufferUsage.UNIFORM => can be used with uniforms
            GPUBufferUsage.COPY_DST => can update by copying data to it
        */
        
        /*
        const uniformBufferSize =
            4 * 4 + // color is 4 32bit floats (4bytes each)
            2 * 4 + // scale is 2 32bit floats (4bytes each)
            2 * 4;  // offset is 2 32bit floats (4bytes each)
        */
        /*
        const uniformBuffer = device.createBuffer({
            size: uniformBufferSize,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
        });
        */

        // Create a typedarray to hold the values for the uniforms in JavaScript
        //const uniformValues = new Float32Array(uniformBufferSize / 4);

        // offsets to the various uniform values in float32 indices
        /*
        const kColorOffset = 0;
        const kScaleOffset = 4;
        const kOffsetOffset = 6;
        */
        // create 2 buffers for the uniform values
        /*
        const staticUniformBufferSize =
            4 * 4 + // color is 4 32bit floats (4bytes each)
            2 * 4 + // offset is 2 32bit floats (4bytes each)
            2 * 4;  // padding
        const uniformBufferSize =
            2 * 4;  // scale is 2 32bit floats (4bytes each)
        
        // offsets to the various uniform values in float32 indices
        const kColorOffset = 0;
        const kOffsetOffset = 4;
        
        const kScaleOffset = 0;

        const kNumObjects = 100;
        const objectInfos = [];
        */
        /*
            We can create one uniform buffer per thing we want to draw. 
            And, since buffers are used indirectly through bind groups, we’ll also need one bind group per thing we want to draw. 
            Then we can put all the things we want to draw into a single command buffer.
        */
        /*
        for (let i = 0; i < kNumObjects; ++i) {
            const uniformBuffer = device.createBuffer({
                label: `uniforms for obj: ${i}`,
                size: uniformBufferSize,
                usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
            });
        
            // create a typedarray to hold the values for the uniforms in JavaScript
            const uniformValues = new Float32Array(uniformBufferSize / 4);
            uniformValues.set([rand(), rand(), rand(), 1], kColorOffset);        // set the color
            uniformValues.set([rand(-0.9, 0.9), rand(-0.9, 0.9)], kOffsetOffset);      // set the offset
        
            const bindGroup = device.createBindGroup({
                label: `bind group for obj: ${i}`,
                layout: pipeline.getBindGroupLayout(0),
                entries: [
                    { binding: 0, resource: { buffer: uniformBuffer }},
                ],
            });
        
            objectInfos.push({
                scale: rand(0.2, 0.5),
                uniformBuffer,
                uniformValues,
                bindGroup,
            });
        }
        */
        /*
        for (let i = 0; i < kNumObjects; ++i) {
            const staticUniformBuffer = device.createBuffer({
                label: `static uniforms for obj: ${i}`,
                size: staticUniformBufferSize,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });
        
            // These are only set once so set them now
            {
                const uniformValues = new Float32Array(staticUniformBufferSize / 4);
                uniformValues.set([rand(), rand(), rand(), 1], kColorOffset);        // set the color
                uniformValues.set([rand(-0.9, 0.9), rand(-0.9, 0.9)], kOffsetOffset);      // set the offset
            
                // copy these values to the GPU
                device.queue.writeBuffer(staticUniformBuffer, 0, uniformValues);
            }
        
            // create a typedarray to hold the values for the uniforms in JavaScript
            const uniformValues = new Float32Array(uniformBufferSize / 4);
            const uniformBuffer = device.createBuffer({
                label: `changing uniforms for obj: ${i}`,
                size: uniformBufferSize,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });
        
            const bindGroup = device.createBindGroup({
            label: `bind group for obj: ${i}`,
            layout: pipeline.getBindGroupLayout(0),
            entries: [
                { binding: 0, resource: { buffer: staticUniformBuffer }},
                { binding: 1, resource: { buffer: uniformBuffer }},
            ],
            });
        
            objectInfos.push({
                scale: rand(0.2, 0.5),
                uniformBuffer,
                uniformValues,
                bindGroup,
            });
        }
        */
        //uniformValues.set([0, 1, 0, 1], kColorOffset);        // set the color (green)
        //uniformValues.set([-0.5, -0.25], kOffsetOffset);      // set the offset for triangle

        // create a bind group and bind the buffer to the same @binding(?) we set in our shader = binding 0
        /*
            const bindGroup = device.createBindGroup({
            layout: pipeline.getBindGroupLayout(0),
            entries: [
            { binding: 0, resource: { buffer: uniformBuffer }},
            ],
        });
        */

        // Vertex attributes do not have the same padding restrictions as structures in storage buffers so we no longer need the padding
        // Since we're no longer using the storage buffers we no longer need the bindGroup
        const kNumObjects = 100;
        const objectInfos = [];
        
        // create 2 storage buffers
        const staticUnitSize =
            4 +     // color is 4 bytes
            2 * 4;  // offset is 2 32bit floats (4bytes each)
        const changingUnitSize =
            2 * 4;  // scale is 2 32bit floats (4bytes each)
        const staticVertexBufferSize = staticUnitSize * kNumObjects;
        const changingVertexBufferSize = changingUnitSize * kNumObjects;
        
        const staticVertexBuffer = device.createBuffer({
            label: 'static vertex for objects',
            size: staticVertexBufferSize,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
        });
        
        const changingVertexBuffer = device.createBuffer({
            label: 'changing vertex for objects',
            size: changingVertexBufferSize,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
        });
        
        // offsets to the various uniform values in float32 indices
        const kColorOffset = 0;
        //const kOffsetOffset = 4;
        const kOffsetOffset = 1;
        
        const kScaleOffset = 0;
        
        {
            const staticVertexValuesU8 = new Uint8Array(staticVertexBufferSize);
            const staticVertexValuesF32 = new Float32Array(staticVertexValuesU8.buffer); // an ArrayViewer to uint8Array
            for (let i = 0; i < kNumObjects; ++i) {
                const staticOffsetU8 = i * staticUnitSize;
                const staticOffsetF32 = staticOffsetU8 / 4;
        
                // These are only set once so set them now
                staticVertexValuesU8.set(        // set the color
                    [rand() * 255, rand() * 255, rand() * 255, 255],
                    staticOffsetU8 + kColorOffset);
            
                staticVertexValuesF32.set(      // set the offset
                    [rand(-0.9, 0.9), rand(-0.9, 0.9)],
                    staticOffsetF32 + kOffsetOffset);
            
                objectInfos.push({
                    scale: rand(0.2, 0.5),
                });
            }
            /*
                device.queue.writeBuffer(
                    destBuffer,  // the buffer to write to
                    destOffset,  // where in the destination buffer to start writing
                    srcData,     // a typedArray or arrayBuffer
                    srcOffset?,  // offset in **elements** in srcData to start copying (default 0)
                    size?,       // size in **elements** of srcData to copy (default size of srcData)
                )
            */
            device.queue.writeBuffer(staticVertexBuffer, 0, staticVertexValuesF32);
            /*
                encoder.copyBufferToBuffer(
                    source,       // buffer to copy from
                    sourceOffset, // where to start copying from
                    dest,         // buffer to copy to
                    destOffset,   // where to start copying to
                    size,         // how many bytes to copy
                )
                source must have a usage of GPUBufferUsage.COPY_SRC
                dest must have a usage of GPUBufferUsage.COPY_DST
                size must be a multiple of 4
            */
        }
        
        // a typed array we can use to update the changingVertexBuffer
        const storageValues = new Float32Array(changingVertexBufferSize / 4);
        
        // setup a storage buffer with vertex data
        const { vertexData, indexData, numVertices } = createCircleVertices({
            radius: 0.5,
            innerRadius: 0.25,
        });
        /*
        const vertexStorageBuffer = device.createBuffer({
            label: 'storage buffer vertices',
            size: vertexData.byteLength,
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
        });
        device.queue.writeBuffer(vertexStorageBuffer, 0, vertexData);
        */
        // GPUBufferUsage.VERTEX => indicates, this is a Vertex buffer
        const vertexBuffer = device.createBuffer({
            label: 'vertex buffer vertices',
            size: vertexData.byteLength,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
        });
        device.queue.writeBuffer(vertexBuffer, 0, vertexData);

        // GPUBufferUsage.INDEX => indicates, this is an Index buffer
        const indexBuffer = device.createBuffer({
            label: 'index buffer',
            size: indexData.byteLength,
            usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST,
        });
        device.queue.writeBuffer(indexBuffer, 0, indexData);

        /*
            GPURenderPassDescriptor
            Describes which textures we want to draw to and how to use them
            colorAttachments => lists the textures we will render to and how to treat them
            clearValue => with which color to clear the canvas/texture
            loadOp: 'clear' => specifies to clear the texture to the clear value before drawing
            loadOp: 'load' => load the existing contents of the texture into the GPU so we can draw over what’s already there 
            storeOp: 'store' => store the result of what we draw
            storeOp: 'discard' => throw away what we draw

            Element 0 of the colorAttachments array corresponds to @location(0) as we specified for the return value of the fragment shader
        */
        // Prepare GPURenderPassDescriptor
        const renderPassDescriptor = {
            label: 'our basic canvas renderPass',
            colorAttachments: [
            {
                // view: <- to be filled out when we render
                clearValue: [0.3, 0.3, 0.3, 1],
                loadOp: 'clear',
                storeOp: 'store',
            },
            ],
        };  

        const canvasToSizeMap = new WeakMap();

        function resizeCanvasToDisplaySize(canvas) {
            // Get the canvas's current display size
            let { width, height } = canvasToSizeMap.get(canvas) || canvas;

            // Make sure it's valid for WebGPU
            width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D));
            height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D));

            // Only if the size is different, set the canvas size
            const needResize = canvas.width !== width || canvas.height !== height;
            if (needResize) {
                canvas.width = width;
                canvas.height = height;
            }
            return needResize;
        }

        // Render
        function render() {
            // Set the uniform values in our JavaScript side Float32Array
            /*
            const aspect = canvas.width / canvas.height;
            uniformValues.set([0.5 / aspect, 0.5], kScaleOffset); // set the scale
        
            // copy the values from JavaScript to the GPU
            device.queue.writeBuffer(uniformBuffer, 0, uniformValues);
            */

            resizeCanvasToDisplaySize(canvas);

            // Get the current texture from the canvas context and set it as the texture to render to.
            renderPassDescriptor.colorAttachments[0].view = context.getCurrentTexture().createView();
        
            // make a command encoder to start encoding commands
            const encoder = device.createCommandEncoder({ label: 'our encoder' });
        
            // make a render pass encoder to encode render specific commands
            const pass = encoder.beginRenderPass(renderPassDescriptor);
            pass.setPipeline(pipeline);
            pass.setVertexBuffer(0, vertexBuffer); // 0 => first element of the render pipeline buffers array
            pass.setVertexBuffer(1, staticVertexBuffer); // second buffer in render pipeline buffers array
            pass.setVertexBuffer(2, changingVertexBuffer);
            pass.setIndexBuffer(indexBuffer, 'uint32');

            // Set the uniform values in our JavaScript side Float32Array
            const aspect = canvas.width / canvas.height;
            
            /*
            for (const {scale, bindGroup, uniformBuffer, uniformValues} of objectInfos) {
                uniformValues.set([scale / aspect, scale], kScaleOffset); // set the scale
                device.queue.writeBuffer(uniformBuffer, 0, uniformValues);
                pass.setBindGroup(0, bindGroup);
                pass.draw(3);  // call our vertex shader 3 times
            }
            */
            // set the scales for each object
            objectInfos.forEach(({scale}, ndx) => {
                const offset = ndx * (changingUnitSize / 4);
                storageValues.set([scale / aspect, scale], offset + kScaleOffset); // set the scale
            });
            // upload all scales at once
            device.queue.writeBuffer(changingVertexBuffer, 0, storageValues);
        
            //pass.draw(3, kNumObjects);  // call our vertex shader 3 times for each instance
            //pass.draw(numVertices, kNumObjects);
            pass.drawIndexed(numVertices, kNumObjects);

            pass.end();
        
            const commandBuffer = encoder.finish();
            device.queue.submit([commandBuffer]);
        }
    
        /*
            <canvas> tags, by default, have a resolution of 300x150 pixels. 
            We’d like to adjust the resolution of the canvas to match the size it is displayed.
            create a ResizeObserver and give it a function to call whenever the elements you’ve asked it to observe change their size. 
            You then tell it which elements to observe.

            We go through all entries, but it should only be one => our one canvas. 
            We need to limit the size of the canvas to the largest size our device supports otherwise WebGPU will start generating errors that we tried to make a texture that is too large. 
            We also need to make sure it doesn’t go to zero or again we’ll get errors.
            
            We call render to re-render the triangle at the new resolution.

            The new size texture is created when we call context.getCurrentTexture() inside render
        */
        const observer = new ResizeObserver(entries => {
            for (const entry of entries) {
                canvasToSizeMap.set(entry.target, {
                    width: entry.contentBoxSize[0].inlineSize,
                    height: entry.contentBoxSize[0].blockSize,
                });
            }
            render();
        });
        observer.observe(canvas);
    }

    function fail(msg) {
    // eslint-disable-next-line no-alert
        alert(msg);
    }
</script>